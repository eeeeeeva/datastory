# Who's Talking about Climate Change?
*nota bene: GitHub does not allow for markdown or html to open links in new tabs, so all links will open in this tab unless you ctrl/right-click to open in a new tab or window*

In April, the Yale Program on Climate Change Communication released a [report](http://climatecommunication.yale.edu/publications/climate-change-american-mind-march-2018/) of data they collected about public conceptions of climate change--what do people think about it? Do people think about it at all? How urgent, despondent, ambivalent, or unconcerned are people feeling about it? For me, a particularly [surprising figure](http://climatecommunication.yale.edu/publications/climate-change-american-mind-march-2018/6/) from the report was that 65% of the polled respondents said that they rarely or never discuss climate change in their daily lives. Of those respondents, 35% of the respondents said that was because the subject never comes up, and 33% because they already agree with their family and friends. As someone who thinks, feels, and talks about climate change every day, whether I intend to or not, and often with people who agree with me, I was curious to find out more about these Americans they polled for whom the concept never or rarely crosses their path.

My engagement with concepts of climate change has largely been through theater, performance, and writing, and this report touched on a premise that motivates my commitment to expressive media as vital tools in the human repair kit: in order to [act and relate](https://www.tikkun.org/nextgen/occupy-the-climate-emergency) differently to the planet and to better contribute to the flourishing of other species (and ourselves), people must cultivate intimate, personal, and strong feelings about this consummate [hyperobject](https://criticalinquiry.uchicago.edu/ursula_k._heise_reviews_timothy_morton). [Intra-active](https://www.youtube.com/watch?v=v0SnstJoEec) well beyond the scope of daily life or human understanding, one way to meet the challenge of grasping climate enough to shape human behavior and decision-making is through the capacity of our emotions. How do we meaningfully empathize with the planet, the various forms of life and experience it hosts, and those [lives](https://www.theguardian.com/us-news/2018/apr/27/al-gore-climate-change-impact-black-poor-people-more) and [experiences](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3880584/) which are [most vulnerable](https://www.theguardian.com/vital-signs/2014/oct/03/ebola-epidemic-bats-deforestation-west-africa-guinea-sierra-leone-liberia) to the [accreted](https://muse.jhu.edu/chapter/833196) [detriments](https://www.dissentmagazine.org/online_articles/hot-bothered-cited-podcast-climate-migration-refugees) of [global capitalism](http://www.jstor.org.proxy-um.researchport.umd.edu/stable/4501730) which furnish climate change? How and what do we learn from that empathy? And how then does a platform like Twitter--a distributed network of human (and [machine](https://www.youtube.com/watch?v=vjuQRCG_sUw)) expressions--unveil the expressed [cares](https://muse.jhu.edu/book/50528) and [concerns](http://www.bruno-latour.fr/sites/default/files/89-CRITICAL-INQUIRY-GB.pdf) of its users and, further, how does it shape the circulation of those attachments on- and off-line? When it comes to climate change, if no one on Tweets about it, does it matter?


## Limitations

*I recognize that the data gathering process I undertook functions almost in opposition to the concern that prompted my research: if I am ultimately curious about those people in the US who do not think or talk about climate change regularly, what will I learn by looking at a record of Twitter mentions? I am reminded of the archival silences elicited in Saidiya Hartman's work, but I am skeptical of the service critical fabulation might provide in this context. In any case, I wonder, (how) can I gather platform participation data on those who are not participating in the conversation? I concede that a more fruitful pursuit will be to evaluate the data that does exist in the Twitter archive. I imagine that interesting lines of inquiry to better understand that silent majority could be to add climate change hashtags to unrelated hashtags and see how they circulate, or to cross reference popular topics of discussion to see if there are correlations among themes that people participating in conversations about climate change also take on (searching for the Curly Fries of climate change) and, vice versa, to see if there are popular topics whose interlocutors do not participate in conversations on climate change. These impulses exceed my technical skills and the scope of the exercise, however, so I try a different tack and ask:* Will twitter data gathered from Twarc reveal any insights about who *is* discussing climate change? and what general feelings are being communicated about it on Twitter, and how participation in that conversation compares to other major cultural topics being discussed on Twitter?

## Data Gathering

Using Twarc to gather data on how people were talking about climate change proved tricky. At first, I tried just searching hashtags, but because this event is an ongoing, [crisis ordinariness](https://lucian.uchicago.edu/blogs/politicalfeeling/files/2009/01/berlant-thinking-about-feeling.pdf), there are not immediately obvious hashtags to search for beyond just "#climatechange" or "#globalwarming" (both of which I tried, to uninteresting results). I tried searching for both "climate change" and "global warming" as keywords and complete phrases, but for some reason, this yielded almost no results. Ultimately, I decided to make my search as broad as possible with the twarc query "twarc search 'climate change', which brought back tens of thousands of results. I limited the scope of the data to just the evening of May 7th, which ended up with a data set of about 6200 entries. I felt no special ethical unease about collecting this data and sharing it on the internet it does not immediately or intentionally relate to the personal identities of the users, and I wonder if that isn't exactly at the heart of the question I am pursuing: why do our expressed beliefs and opinions on climate change feel less threatening to be captured and displayed than our views on race or religion or gender or sexuality? The perceived lack of risk to individual subjectivity makes this issue both less concerning as a potential "outing," and reveals the general lack of *personal* investment in climate change.

## Investigations

My first instinct was to look at tweet types: how many of these 6200 tweets were original, versus retweets or quotes. Unsurprisingly, perhaps, there were 4 times as many retweets (4409) as original ones (1146), with relatively few responses (536) and quotes (135). I wonder if this says more about how people participate in Twitter more broadly than anything specifically about this dataset? Then I separated out all the hashtags and looked at which were most prevalent, and was not sure what to make of what I found--the [most recent climate event](https://www.npr.org/sections/thetwo-way/2018/05/08/609503580/days-weeks-years-scientists-say-hawaiis-erupting-volcano-has-no-end-in-sight) to capture the media's attention featured prominently, #snl was popular as there had been a joke on Saturday Night Live this weekend about climate change, and it would not be Twitter without some right wing conspiracy theories about the deep state (thank you, #RiggedDiplomacy). I was interested in but could not figure out how to look for which hashtags were closely associated with one another. I was curious to use the sentiment analysis tools in the Text Analysis plug-in to determine the feelings expressed in the tweets themselves, and also in the Twitter bios of the Tweeters, but I had used my free credit for another project and would have had to pay into the app in order to use it. I tried an external program called [Monkey Learn](https://monkeylearn.com/), which was extremely interesting, as the user has to standardize the data set by evaluating samples. After standardizing about 80 samples, however, I realized that I needed better theorized sentiment categories, as the tool was not able to learn how to analyze the data according to the default categories of "happy," "angry," "neutral." and "amused" (nor was I).
